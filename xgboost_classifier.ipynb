{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/wvby4kh52j96myw15h33jjk40000gn/T/ipykernel_53915/3229613841.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Users/I748920/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to 'top_30_stocks_long_only.csv' and 'top_30_stocks_long_short.csv'\n",
      "\n",
      "Detailed metrics for top stock (Long-Only Strategy) SMCI:\n",
      "Final Close Price: 284.26\n",
      "60-day Return: 250.61%\n",
      "Average Hourly Volatility: 0.6678\n",
      "Average Sharpe Ratio: 1.6242\n",
      "Average Hourly Volume: 355714\n",
      "\n",
      "num common_top_stocks:  35\n"
     ]
    }
   ],
   "source": [
    "from scripts.get_top_stocks import *\n",
    "top_stocks_long, top_stocks_long_short = generate_top_stocks_df()\n",
    "common_top_stocks = get_common_top_stocks(top_stocks_long, top_stocks_long_short)\n",
    "\n",
    "# specify variables for dataset generation\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2024-08-01'\n",
    "interval = \"1h\"\n",
    "trading_days_per_year = 252\n",
    "hours_per_day = 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from scripts.generate_dataset_features import *\n",
    "\n",
    "\n",
    "df = get_all_stock_features_df(\n",
    "    stocks_list=common_top_stocks,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    interval=interval,\n",
    "    trading_days_per_year=trading_days_per_year, \n",
    "    hours_per_day=hours_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Log_Return</th>\n",
       "      <th>EMAVolumeDiff2</th>\n",
       "      <th>SMAVolumeDiff2</th>\n",
       "      <th>...</th>\n",
       "      <th>MACD16</th>\n",
       "      <th>MACD32</th>\n",
       "      <th>MACD64</th>\n",
       "      <th>MACD128</th>\n",
       "      <th>MACD256</th>\n",
       "      <th>FamaFrenchMktReturns</th>\n",
       "      <th>Log_Return_shift</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>Stock_Position</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-24 13:30:00-05:00</td>\n",
       "      <td>34.439999</td>\n",
       "      <td>34.537498</td>\n",
       "      <td>34.380001</td>\n",
       "      <td>34.455002</td>\n",
       "      <td>34.455002</td>\n",
       "      <td>430096</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.237227</td>\n",
       "      <td>0.377802</td>\n",
       "      <td>...</td>\n",
       "      <td>2.959740</td>\n",
       "      <td>-0.088659</td>\n",
       "      <td>-0.726666</td>\n",
       "      <td>-3.268206</td>\n",
       "      <td>-37.998322</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>CPRT</td>\n",
       "      <td>buy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-24 14:30:00-05:00</td>\n",
       "      <td>34.450001</td>\n",
       "      <td>34.634998</td>\n",
       "      <td>34.410000</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>694483</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.199732</td>\n",
       "      <td>0.235099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.570454</td>\n",
       "      <td>0.152135</td>\n",
       "      <td>21.164271</td>\n",
       "      <td>35.817040</td>\n",
       "      <td>10.515641</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>CPRT</td>\n",
       "      <td>hold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-24 15:30:00-05:00</td>\n",
       "      <td>34.610001</td>\n",
       "      <td>34.634998</td>\n",
       "      <td>34.455002</td>\n",
       "      <td>34.615002</td>\n",
       "      <td>34.615002</td>\n",
       "      <td>456536</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>-0.081993</td>\n",
       "      <td>-0.206727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.579874</td>\n",
       "      <td>0.162966</td>\n",
       "      <td>5.581055</td>\n",
       "      <td>16.741564</td>\n",
       "      <td>9.517186</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>CPRT</td>\n",
       "      <td>buy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-27 09:30:00-05:00</td>\n",
       "      <td>34.895000</td>\n",
       "      <td>35.020000</td>\n",
       "      <td>34.740002</td>\n",
       "      <td>34.942501</td>\n",
       "      <td>34.942501</td>\n",
       "      <td>181650</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>-0.366788</td>\n",
       "      <td>-0.430730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050891</td>\n",
       "      <td>0.093693</td>\n",
       "      <td>0.346850</td>\n",
       "      <td>1.293227</td>\n",
       "      <td>2.683604</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>CPRT</td>\n",
       "      <td>sell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-27 10:30:00-05:00</td>\n",
       "      <td>34.930000</td>\n",
       "      <td>34.930000</td>\n",
       "      <td>34.695000</td>\n",
       "      <td>34.724998</td>\n",
       "      <td>34.724998</td>\n",
       "      <td>108775</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>-0.353070</td>\n",
       "      <td>-0.250925</td>\n",
       "      <td>...</td>\n",
       "      <td>2.594881</td>\n",
       "      <td>0.522353</td>\n",
       "      <td>1.372016</td>\n",
       "      <td>3.948259</td>\n",
       "      <td>5.474724</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>CPRT</td>\n",
       "      <td>buy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime       Open       High        Low      Close  \\\n",
       "0  2023-02-24 13:30:00-05:00  34.439999  34.537498  34.380001  34.455002   \n",
       "1  2023-02-24 14:30:00-05:00  34.450001  34.634998  34.410000  34.599998   \n",
       "2  2023-02-24 15:30:00-05:00  34.610001  34.634998  34.455002  34.615002   \n",
       "3  2023-02-27 09:30:00-05:00  34.895000  35.020000  34.740002  34.942501   \n",
       "4  2023-02-27 10:30:00-05:00  34.930000  34.930000  34.695000  34.724998   \n",
       "\n",
       "   Adj Close  Volume  Log_Return  EMAVolumeDiff2  SMAVolumeDiff2  ...  \\\n",
       "0  34.455002  430096    0.000363        0.237227        0.377802  ...   \n",
       "1  34.599998  694483    0.004199        0.199732        0.235099  ...   \n",
       "2  34.615002  456536    0.000434       -0.081993       -0.206727  ...   \n",
       "3  34.942501  181650    0.009417       -0.366788       -0.430730  ...   \n",
       "4  34.724998  108775   -0.006244       -0.353070       -0.250925  ...   \n",
       "\n",
       "     MACD16    MACD32     MACD64    MACD128    MACD256  FamaFrenchMktReturns  \\\n",
       "0  2.959740 -0.088659  -0.726666  -3.268206 -37.998322                 -1.09   \n",
       "1 -0.570454  0.152135  21.164271  35.817040  10.515641                 -1.09   \n",
       "2 -0.579874  0.162966   5.581055  16.741564   9.517186                 -1.09   \n",
       "3  0.050891  0.093693   0.346850   1.293227   2.683604                  0.31   \n",
       "4  2.594881  0.522353   1.372016   3.948259   5.474724                  0.31   \n",
       "\n",
       "   Log_Return_shift  stock_name  Stock_Position  Target  \n",
       "0          0.004199        CPRT             buy       2  \n",
       "1          0.000434        CPRT            hold       1  \n",
       "2          0.009417        CPRT             buy       2  \n",
       "3         -0.006244        CPRT            sell       0  \n",
       "4          0.003019        CPRT             buy       2  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "1.0    30558\n",
       "0.0    29656\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# additional logic to ensure buy remains +ve and sell remainvs -ve\n",
    "\n",
    "print(len(df[(df.Log_Return_shift < 0) & (df.Stock_Position == 'buy')]))\n",
    "print(len(df[(df.Log_Return_shift < 0) & (df.Stock_Position == 'strong buy')]))\n",
    "\n",
    "print(len(df[(df.Log_Return_shift > 0) & (df.Stock_Position == 'sell')]))\n",
    "print(len(df[(df.Log_Return_shift > 0) & (df.Stock_Position == 'strong sell')]))\n",
    "\n",
    "# all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Log_Return_shift'], axis=1, inplace=True)\n",
    "df['Target'] = df['Target'].map({1:0, 2:1, 3:2})\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Target'\n",
    "features = df.columns[8:-1]\n",
    "features = features.drop('stock_name')\n",
    "features = features.drop('Stock_Position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48171, 83), (6021, 83), (6022, 83))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort df according to date\n",
    "# df1 = df.sort_values(\"Datetime\").reset_index(drop=True)\n",
    "df1 = df.sort_values(\"Datetime\").reset_index(drop=True)\n",
    "# train test split on index\n",
    "train_size, val_size, test_size = 0.8, 0.1, 0.1\n",
    "train_size, val_size, test_size = int(len(df1) * train_size), int(len(df1) * val_size), int(len(df1) * test_size)\n",
    "train_df = df1.iloc[:train_size]\n",
    "val_df = df1.iloc[train_size:train_size + val_size]\n",
    "test_df = df1.iloc[train_size + val_size:]\n",
    "\n",
    "train_df.shape,val_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "1.0    3047\n",
       "0.0    2975\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numpy = df[features].to_numpy()\n",
    "target_numpy = df[target].to_numpy()\n",
    "# features = features.drop('Target')\n",
    "X_train = train_df[features].to_numpy()\n",
    "y_train = train_df[target].to_numpy()\n",
    "print(X_train.shape,y_train.shape)\n",
    "\n",
    "X_val = val_df[features].to_numpy()\n",
    "y_val = val_df[target].to_numpy()\n",
    "print(X_val.shape,y_val.shape)\n",
    "\n",
    "X_test = test_df[features].to_numpy()\n",
    "y_test = test_df[target].to_numpy()\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.train_predict import *\n",
    "\n",
    "# standardise the values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation data\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape,y_train.shape,X_val.shape,y_val.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# from tqdm import tqdm\n",
    "from alive_progress import alive_it\n",
    "\n",
    "def train():\n",
    "    # initialise training params\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "\n",
    "    # Define the parameter grid\n",
    "    # param_grid={\"learning_rate\": (0.05, 0.10, 0.15),\n",
    "    #             \"max_depth\": [ 3, 4, 6, 8],\n",
    "    #             \"min_samples_leaf\": [0.001, 0.05, 0.1],\n",
    "    #             \"n_estimators\": [100, 200, 500]\n",
    "    #             },\n",
    "    param_grid = {\n",
    "        'eta': [0.1, 0.3, 0.5],\n",
    "        'gamma': [0, ],\n",
    "        'max_depth': [6, 8],\n",
    "    }\n",
    "    # best_model = xgb.XGBClassifier()\n",
    "    # best_model.fit(X_train, y_train)\n",
    "    # y_pred = best_model.predict(X_val)\n",
    "    # best_score = accuracy_score(y_val, y_pred)\n",
    "    # best_params = 0\n",
    "    for params in alive_it(ParameterGrid(param_grid)):\n",
    "        model = xgb.XGBClassifier(**params) # initialise new model before each run\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        score = accuracy_score(y_val, y_pred)\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "            print(f\"score: {round(best_score,7)}\")\n",
    "            # print(f\"score: {round(best_score,7)}, params: {best_params}\")\n",
    "\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "    print(f\"Best validation score: {round(best_score,5)}\")\n",
    "\n",
    "    return best_model, best_params, best_score, X_test, y_test\n",
    "\n",
    "def predict(best_model,X_test, y_test):\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test set accuracy score: {round(score,5)}\")\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def train_predict():\n",
    "    best_model, best_params, best_score, X_test, y_test = train()\n",
    "    y_pred = predict(best_model, X_test, y_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    " \n",
    "    \n",
    "    return best_model, best_params, best_score, acc, y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_params, best_score, acc, y_pred = train_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(f\"accuracy: {round(acc*100,2)}\")\n",
    "labels = ['sell', 'hold', 'buy']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = test_df[test_df['stock_name']=='LRCX']\n",
    "stock_X_test = stock_df[features].to_numpy()\n",
    "stock_y_test = stock_df[target].to_numpy()\n",
    "stock_preds = best_model.predict(stock_X_test)\n",
    "acc = accuracy_score(stock_y_test, stock_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in test_df.stock_name.unique():\n",
    "    stock_df = test_df[test_df['stock_name']==ticker]\n",
    "    stock_X_test = stock_df[features].to_numpy()\n",
    "    stock_y_test = stock_df[target].to_numpy()\n",
    "    stock_preds = best_model.predict(stock_X_test)\n",
    "    acc = accuracy_score(stock_y_test, stock_preds)\n",
    "\n",
    "    print(f\"{ticker}: {round(acc*100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa5205-env",
   "language": "python",
   "name": "dsa5205-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
